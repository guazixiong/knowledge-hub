# 🚀 企业级知识中台实施方案与验收标准

基于 LangChain + Dify 架构的企业级知识中台完整实施方案

## 📋 项目概述

### 项目目标
构建一个基于 LangChain 和 Dify 的企业级知识中台解决方案，支持多知识库管理、智能文档处理和语义检索。

### 技术架构
- **后端**: FastAPI + LangChain + ChromaDB
- **前端**: React + TypeScript + Ant Design
- **AI集成**: OpenAI Embeddings + Dify工作流
- **部署**: Docker + Nginx

### 预计工期
**总工期**: 8-12周（根据团队规模调整）

---

## 🎯 第一阶段：环境准备与基础架构搭建

### 📅 时间安排
**预计工期**: 1-2周

### 🎯 主要任务

#### 1.1 项目结构创建

```bash
```

#### 1.2 开发环境配置
- **Python 环境**: 3.10+
- **Node.js 环境**: 16+
- **IDE 配置**: VSCode + Python/TypeScript 插件
- **Git 配置**: 分支策略、提交规范

#### 1.3 依赖包安装
```bash
# 后端依赖
pip install fastapi==0.104.1 uvicorn==0.24.0 
pip install langchain==0.1.0 langchain-community==0.0.10
pip install openai==1.6.1 chromadb==0.4.18
pip install unstructured==0.11.8 python-multipart==0.0.6
pip install aiofiles==23.2.1 pydantic-settings==2.1.0
pip install watchdog==3.0.0 pytest==7.4.3
pip install minio==7.2.0 boto3==1.34.0  # MinIO 对象存储

# 前端依赖
cd frontend
npm install react@18.2.0 @types/react@18.2.45
npm install antd@5.12.8 @ant-design/icons@5.2.6
npm install axios@1.6.2 zustand@4.4.7
npm install @types/node@20.10.4 typescript@5.3.3
```

#### 1.4 MinIO 对象存储部署

**目标**: 部署本地 MinIO 服务器用于文档文件存储

##### 1.4.1 Docker 方式部署 MinIO (推荐)
```bash
# 1. 创建 MinIO 数据目录
mkdir -p ./data/minio/{data,config}

# 2. 使用 Docker 启动 MinIO
docker run -d \
  --name minio-server \
  -p 9000:9000 \
  -p 9001:9001 \
  -e "MINIO_ROOT_USER=minioadmin" \
  -e "MINIO_ROOT_PASSWORD=minioadmin123" \
  -v ./data/minio/data:/data \
  -v ./data/minio/config:/root/.minio \
  minio/minio server /data --console-address ":9001"

# 3. 验证 MinIO 服务
curl http://localhost:9000/minio/health/live
```

##### 1.4.2 Docker Compose 方式部署
创建 `docker-compose.minio.yml`:
```yaml
version: '3.8'

services:
  minio:
    image: minio/minio:latest
    container_name: knowledge-hub-minio
    ports:
      - "9000:9000"    # API 端口
      - "9001:9001"    # Web 控制台端口
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001
    volumes:
      - ./data/minio/data:/data
      - ./data/minio/config:/root/.minio
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - knowledge-hub-network

networks:
  knowledge-hub-network:
    driver: bridge
```

启动命令:
```bash
docker-compose -f docker-compose.minio.yml up -d
```

##### 1.4.3 MinIO 客户端配置
```bash
# 安装 MinIO 客户端 (可选)
# Windows
curl -O https://dl.min.io/client/mc/release/windows-amd64/mc.exe

# Linux/Mac
curl -O https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc

# 配置 MinIO 客户端
./mc alias set local http://localhost:9000 minioadmin minioadmin123

# 创建存储桶
./mc mb local/knowledge-hub-docs
./mc mb local/knowledge-hub-uploads
```

##### 1.4.4 MinIO Python 客户端配置
```python
# backend/core/minio_client.py
from minio import Minio
from minio.error import S3Error
import os
from typing import Optional
import logging

class MinIOClient:
    def __init__(self):
        self.client = Minio(
            endpoint=os.getenv("MINIO_ENDPOINT", "localhost:9000"),
            access_key=os.getenv("MINIO_ACCESS_KEY", "minioadmin"),
            secret_key=os.getenv("MINIO_SECRET_KEY", "minioadmin123"),
            secure=False  # 本地开发环境使用 HTTP
        )
        self.bucket_name = os.getenv("MINIO_BUCKET", "knowledge-hub-docs")
        self.logger = logging.getLogger(__name__)
        
        # 确保存储桶存在
        self._ensure_bucket_exists()
    
    def _ensure_bucket_exists(self):
        """确保存储桶存在"""
        try:
            if not self.client.bucket_exists(self.bucket_name):
                self.client.make_bucket(self.bucket_name)
                self.logger.info(f"Created bucket: {self.bucket_name}")
        except S3Error as e:
            self.logger.error(f"Error creating bucket: {e}")
    
    def upload_file(self, file_path: str, object_name: str) -> bool:
        """上传文件到 MinIO"""
        try:
            self.client.fput_object(
                bucket_name=self.bucket_name,
                object_name=object_name,
                file_path=file_path
            )
            self.logger.info(f"File uploaded: {object_name}")
            return True
        except S3Error as e:
            self.logger.error(f"Error uploading file: {e}")
            return False
    
    def download_file(self, object_name: str, file_path: str) -> bool:
        """从 MinIO 下载文件"""
        try:
            self.client.fget_object(
                bucket_name=self.bucket_name,
                object_name=object_name,
                file_path=file_path
            )
            return True
        except S3Error as e:
            self.logger.error(f"Error downloading file: {e}")
            return False
    
    def delete_file(self, object_name: str) -> bool:
        """删除 MinIO 中的文件"""
        try:
            self.client.remove_object(self.bucket_name, object_name)
            return True
        except S3Error as e:
            self.logger.error(f"Error deleting file: {e}")
            return False
    
    def get_file_url(self, object_name: str, expires: int = 3600) -> Optional[str]:
        """获取文件的预签名 URL"""
        try:
            url = self.client.presigned_get_object(
                bucket_name=self.bucket_name,
                object_name=object_name,
                expires=expires
            )
            return url
        except S3Error as e:
            self.logger.error(f"Error generating URL: {e}")
            return None
```

#### 1.5 基础配置文件
- **环境变量配置** (.env)
- **数据库配置** (database.py)
- **日志配置** (logging.conf)
- **API 文档配置** (FastAPI Swagger)

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| 项目结构 | 所有目录和文件按规范创建 | 检查目录结构完整性 |
| 环境配置 | Python 3.10+, Node.js 16+ 正常运行 | `python --version`, `node --version` |
| 依赖安装 | 所有依赖包成功安装，无版本冲突 | `pip list`, `npm list` |
| 基础服务 | FastAPI 服务能正常启动 | 访问 http://localhost:8000/docs |
| 前端服务 | React 开发服务器正常启动 | 访问 http://localhost:3000 |
| 配置文件 | 环境变量、数据库配置正确 | 配置文件语法检查 |

---

## 🎯 第二阶段：数据中台后端开发

### 📅 时间安排
**预计工期**: 2-3周

### 🎯 主要任务

#### 完整 API 列表

```python
# ==================== 知识库管理 ====================
POST   /api/kb/create                    # 创建知识库
GET    /api/kb/list                      # 获取知识库列表
GET    /api/kb/{kb_id}/info              # 获取知识库详情
PUT    /api/kb/{kb_id}/update            # 更新知识库配置
DELETE /api/kb/{kb_id}                   # 删除知识库

# ==================== 文档管理 ====================
POST   /api/kb/{kb_id}/documents/upload  # 上传文档（支持批量）
GET    /api/kb/{kb_id}/documents         # 获取文档列表
GET    /api/kb/{kb_id}/documents/{doc_id} # 获取文档详情
DELETE /api/kb/{kb_id}/documents/{doc_id} # 删除文档
PUT    /api/kb/{kb_id}/documents/{doc_id}/reprocess # 重新处理文档

# ==================== 检索接口（供 Dify 调用） ====================
POST   /api/retrieve                     # 语义检索
POST   /api/retrieve/multi               # 多知识库联合检索

# ==================== 监控与维护 ====================
GET    /api/system/stats                 # 系统统计信息
GET    /api/kb/{kb_id}/stats             # 知识库统计
POST   /api/maintenance/backup           # 触发备份
POST   /api/maintenance/cleanup          # 清理旧版本
```

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| API 框架 | FastAPI 服务正常启动，Swagger 文档可访问 | 访问 /docs 页面 |
| 知识库 API | 创建、查询、删除知识库接口正常工作 | Postman/curl 测试 |
| 文档 API | 文档上传、列表、删除接口正常工作 | 文件上传测试 |
| 检索 API | 检索接口返回正确格式的数据 | API 响应格式验证 |
| 错误处理 | 异常情况返回合适的 HTTP 状态码 | 错误场景测试 |
| API 文档 | 所有接口都有完整的文档说明 | Swagger 文档完整性 |

---

## 🎯 第三阶段：LangChain处理层开发

### 📅 时间安排
**预计工期**: 2-3周

### 🎯 主要任务

#### 3.1 文档解析器实现
```python
# core/langchain_processor.py
from langchain.document_loaders import (
    UnstructuredFileLoader,
    UnstructuredWordDocumentLoader,
    UnstructuredPDFLoader,
    UnstructuredMarkdownLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from typing import List, Dict
import os

class DocumentProcessor:
    def __init__(self, config: Dict):
        self.config = config
        self.embeddings = OpenAIEmbeddings(
            model=config.get('embedding_model', 'text-embedding-3-small')
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.get('chunk_size', 1000),
            chunk_overlap=config.get('chunk_overlap', 200),
            separators=["\n\n", "\n", "。", "!", "?", "；", "……", "…", " "]
        )
    
    def load_document(self, file_path: str):
        """根据文件类型选择合适的加载器"""
        file_ext = os.path.splitext(file_path)[1].lower()
        
        loaders = {
            '.txt': UnstructuredFileLoader,
            '.md': UnstructuredMarkdownLoader,
            '.docx': UnstructuredWordDocumentLoader,
            '.pdf': UnstructuredPDFLoader,
            '.html': UnstructuredFileLoader,
        }
        
        loader_class = loaders.get(file_ext, UnstructuredFileLoader)
        loader = loader_class(file_path)
        return loader.load()
    
    def split_documents(self, documents):
        """智能分块处理"""
        return self.text_splitter.split_documents(documents)
    
    def extract_embeddings(self, texts: List[str]):
        """批量向量化"""
        return self.embeddings.embed_documents(texts)
```

#### 3.2 元数据提取器
```python
# utils/metadata_extractor.py
import re
from pathlib import Path
from typing import Dict
from datetime import datetime

class MetadataExtractor:
    def __init__(self):
        self.system_patterns = {
            'CRM': r'(?i)(crm|客户关系|客户管理)',
            'ERP': r'(?i)(erp|企业资源|资源规划)',
            'OA': r'(?i)(oa|办公自动化|协同办公)',
            'HRM': r'(?i)(hrm|人力资源|人事管理)'
        }
        
        self.doc_type_patterns = {
            '需求文档': r'(?i)(需求|requirement|需求分析|业务需求)',
            '设计文档': r'(?i)(设计|design|架构设计|详细设计)',
            '运维文档': r'(?i)(运维|operation|部署|维护)',
            '用户手册': r'(?i)(用户手册|使用说明|操作指南)',
            '技术文档': r'(?i)(技术|technical|开发|api)'
        }
    
    def extract_from_filename(self, file_path: str) -> Dict:
        """从文件名提取元数据"""
        filename = Path(file_path).stem
        metadata = {
            'filename': filename,
            'file_ext': Path(file_path).suffix,
            'system': 'unknown',
            'doc_type': 'unknown',
            'version': '1.0'
        }
        
        # 提取系统名称
        for system, pattern in self.system_patterns.items():
            if re.search(pattern, filename):
                metadata['system'] = system
                break
        
        # 提取文档类型
        for doc_type, pattern in self.doc_type_patterns.items():
            if re.search(pattern, filename):
                metadata['doc_type'] = doc_type
                break
        
        # 提取版本号
        version_match = re.search(r'v?(\d+\.\d+)', filename)
        if version_match:
            metadata['version'] = version_match.group(1)
        
        return metadata
    
    def extract_from_content(self, content: str) -> Dict:
        """从文档内容提取元数据"""
        metadata = {}
        
        # 提取标题
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        if title_match:
            metadata['title'] = title_match.group(1).strip()
        
        # 提取作者
        author_match = re.search(r'作者[:：]\s*(.+)', content)
        if author_match:
            metadata['author'] = author_match.group(1).strip()
        
        # 提取日期
        date_match = re.search(r'(\d{4}[-/]\d{1,2}[-/]\d{1,2})', content)
        if date_match:
            metadata['date'] = date_match.group(1)
        
        return metadata
```

#### 3.3 文档处理任务队列
```python
# core/task_processor.py
import asyncio
from typing import Dict, List
import json
import logging

class DocumentTaskProcessor:
    def __init__(self):
        self.task_queue = asyncio.Queue()
        self.processing_tasks = {}
        self.logger = logging.getLogger(__name__)
    
    async def add_task(self, task_data: Dict):
        """添加文档处理任务"""
        await self.task_queue.put(task_data)
        self.logger.info(f"Task added: {task_data['doc_id']}")
    
    async def process_document_task(self, task_data: Dict):
        """处理单个文档任务"""
        doc_id = task_data['doc_id']
        kb_id = task_data['kb_id']
        file_path = task_data['file_path']
        
        try:
            # 更新任务状态
            self.processing_tasks[doc_id] = {
                'status': 'processing',
                'progress': 0,
                'message': '开始处理文档'
            }
            
            # 1. 加载文档
            processor = DocumentProcessor(task_data['config'])
            documents = processor.load_document(file_path)
            
            self.processing_tasks[doc_id]['progress'] = 25
            self.processing_tasks[doc_id]['message'] = '文档加载完成'
            
            # 2. 提取元数据
            extractor = MetadataExtractor()
            base_metadata = extractor.extract_from_filename(file_path)
            content_metadata = extractor.extract_from_content(documents[0].page_content)
            metadata = {**base_metadata, **content_metadata, 'doc_id': doc_id}
            
            self.processing_tasks[doc_id]['progress'] = 50
            self.processing_tasks[doc_id]['message'] = '元数据提取完成'
            
            # 3. 文档分块
            chunks = processor.split_documents(documents)
            
            self.processing_tasks[doc_id]['progress'] = 75
            self.processing_tasks[doc_id]['message'] = f'文档分块完成，共{len(chunks)}个块'
            
            # 4. 向量化并存储
            await self.store_chunks(kb_id, doc_id, chunks, metadata, processor)
            
            # 5. 完成任务
            self.processing_tasks[doc_id] = {
                'status': 'completed',
                'progress': 100,
                'message': f'处理完成，共生成{len(chunks)}个文档块',
                'chunk_count': len(chunks)
            }
            
            self.logger.info(f"Document {doc_id} processed successfully")
            
        except Exception as e:
            self.processing_tasks[doc_id] = {
                'status': 'failed',
                'progress': 0,
                'message': f'处理失败: {str(e)}'
            }
            self.logger.error(f"Error processing document {doc_id}: {e}")
    
    async def store_chunks(self, kb_id: str, doc_id: str, chunks, metadata: Dict, processor):
        """存储文档块到向量数据库"""
        # 实现向量存储逻辑
        pass
    
    def get_task_status(self, doc_id: str) -> Dict:
        """获取任务状态"""
        return self.processing_tasks.get(doc_id, {'status': 'not_found'})
```

#### 3.3 MinIO 文件存储 API 接口
```python
# api/files.py - MinIO 文件存储接口
from fastapi import APIRouter, UploadFile, File, HTTPException, Query
from fastapi.responses import StreamingResponse
from core.minio_client import MinIOClient
from typing import Optional, List
import uuid
import os
from datetime import datetime

router = APIRouter(prefix="/api/files", tags=["files"])
minio_client = MinIOClient()

@router.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    kb_id: Optional[str] = None,
    folder: Optional[str] = None
):
    """
    上传文件到 MinIO 存储
    
    Args:
        file: 上传的文件
        kb_id: 知识库ID（可选）
        folder: 文件夹路径（可选）
    
    Returns:
        文件信息和访问URL
    """
    try:
        # 生成唯一文件ID
        file_id = str(uuid.uuid4())
        file_ext = os.path.splitext(file.filename)[1]
        
        # 构建对象名称
        if folder:
            object_name = f"{folder}/{file_id}{file_ext}"
        elif kb_id:
            object_name = f"kb_{kb_id}/{file_id}{file_ext}"
        else:
            object_name = f"uploads/{file_id}{file_ext}"
        
        # 保存临时文件
        temp_file_path = f"/tmp/{file_id}{file_ext}"
        with open(temp_file_path, "wb") as temp_file:
            content = await file.read()
            temp_file.write(content)
        
        # 上传到 MinIO
        success = minio_client.upload_file(temp_file_path, object_name)
        
        # 清理临时文件
        os.remove(temp_file_path)
        
        if not success:
            raise HTTPException(status_code=500, detail="文件上传失败")
        
        # 生成预签名URL
        file_url = minio_client.get_file_url(object_name, expires=3600)
        
        return {
            "success": True,
            "file_id": file_id,
            "filename": file.filename,
            "object_name": object_name,
            "file_url": file_url,
            "size": len(content),
            "upload_time": datetime.now().isoformat(),
            "kb_id": kb_id
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"上传失败: {str(e)}")

@router.get("/{file_id}/download")
async def download_file(file_id: str, object_name: str = Query(...)):
    """
    下载文件
    
    Args:
        file_id: 文件ID
        object_name: MinIO中的对象名称
    
    Returns:
        文件流
    """
    try:
        # 下载到临时文件
        temp_file_path = f"/tmp/download_{file_id}"
        success = minio_client.download_file(object_name, temp_file_path)
        
        if not success:
            raise HTTPException(status_code=404, detail="文件不存在")
        
        # 返回文件流
        def file_generator():
            with open(temp_file_path, "rb") as file:
                while True:
                    chunk = file.read(8192)
                    if not chunk:
                        break
                    yield chunk
            # 清理临时文件
            os.remove(temp_file_path)
        
        return StreamingResponse(
            file_generator(),
            media_type="application/octet-stream",
            headers={"Content-Disposition": f"attachment; filename={file_id}"}
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"下载失败: {str(e)}")

@router.get("/{file_id}/url")
async def get_file_url(
    file_id: str,
    object_name: str = Query(...),
    expires: int = Query(3600, description="URL过期时间（秒）")
):
    """
    获取文件的预签名访问URL
    
    Args:
        file_id: 文件ID
        object_name: MinIO中的对象名称
        expires: URL过期时间（秒）
    
    Returns:
        预签名URL
    """
    try:
        file_url = minio_client.get_file_url(object_name, expires)
        
        if not file_url:
            raise HTTPException(status_code=404, detail="文件不存在")
        
        return {
            "success": True,
            "file_id": file_id,
            "file_url": file_url,
            "expires_in": expires
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"获取URL失败: {str(e)}")

@router.delete("/{file_id}")
async def delete_file(file_id: str, object_name: str = Query(...)):
    """
    删除文件
    
    Args:
        file_id: 文件ID
        object_name: MinIO中的对象名称
    
    Returns:
        删除结果
    """
    try:
        success = minio_client.delete_file(object_name)
        
        if not success:
            raise HTTPException(status_code=404, detail="文件不存在或删除失败")
        
        return {
            "success": True,
            "message": f"文件 {file_id} 删除成功"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"删除失败: {str(e)}")

@router.get("/list")
async def list_files(
    kb_id: Optional[str] = Query(None, description="知识库ID"),
    folder: Optional[str] = Query(None, description="文件夹路径"),
    limit: int = Query(50, description="返回数量限制")
):
    """
    获取文件列表
    
    Args:
        kb_id: 知识库ID（可选）
        folder: 文件夹路径（可选）
        limit: 返回数量限制
    
    Returns:
        文件列表
    """
    try:
        # 构建前缀
        if folder:
            prefix = f"{folder}/"
        elif kb_id:
            prefix = f"kb_{kb_id}/"
        else:
            prefix = ""
        
        # 获取文件列表（这里需要扩展 MinIOClient 类）
        # 由于 minio-py 的限制，这里提供一个简化的实现
        return {
            "success": True,
            "files": [],
            "message": "文件列表功能需要进一步实现"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"获取文件列表失败: {str(e)}")
```

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| 文档解析 | 支持 .txt, .md, .docx, .pdf, .html 格式 | 各格式文档解析测试 |
| 智能分块 | 按语义边界分块，块大小控制在设定范围 | 分块结果检查 |
| 元数据提取 | 自动提取文件名、内容中的系统、类型、版本信息 | 元数据准确性验证 |
| 向量化 | 文本成功转换为向量，维度正确 | 向量维度和格式检查 |
| 异步处理 | 文档处理任务异步执行，状态可查询 | 任务状态查询测试 |
| 错误处理 | 处理失败时有详细错误信息 | 异常文档处理测试 |
| MinIO 文件上传 | 文件成功上传到 MinIO，返回访问URL | 文件上传测试 |
| MinIO 文件下载 | 能够通过API下载已上传的文件 | 文件下载测试 |
| MinIO 文件删除 | 能够删除 MinIO 中的文件 | 文件删除测试 |
| 预签名URL | 能够生成有效的文件访问URL | URL访问测试 |

---

## 🎯 第四阶段：向量数据库集成

### 📅 时间安排
**预计工期**: 1-2周

### 🎯 主要任务

#### 4.1 ChromaDB 持久化配置
```python
# core/database.py
import chromadb
from chromadb.config import Settings
from typing import Dict, List, Optional
import os
import json

class VectorDatabase:
    def __init__(self, kb_id: str, config: Dict):
        self.kb_id = kb_id
        self.config = config
        self.db_path = f"./knowledge_bases/{kb_id}/db"
        
        # 确保目录存在
        os.makedirs(self.db_path, exist_ok=True)
        
        # 创建持久化客户端
        self.client = chromadb.PersistentClient(
            path=self.db_path,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # 获取或创建集合
        self.collection = self.client.get_or_create_collection(
            name=f"{kb_id}_documents",
            metadata={"kb_id": kb_id}
        )
    
    def add_documents(self, documents: List[str], metadatas: List[Dict], 
                     embeddings: List[List[float]], ids: List[str]):
        """批量添加文档"""
        try:
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                embeddings=embeddings,
                ids=ids
            )
            return True
        except Exception as e:
            print(f"Error adding documents: {e}")
            return False
    
    def query_documents(self, query_embedding: List[float], 
                       n_results: int = 5, where: Optional[Dict] = None):
        """查询相似文档"""
        try:
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=where,
                include=["documents", "metadatas", "distances"]
            )
            return results
        except Exception as e:
            print(f"Error querying documents: {e}")
            return None
    
    def delete_document(self, doc_id: str):
        """删除文档的所有块"""
        try:
            # 查找该文档的所有块
            results = self.collection.get(
                where={"doc_id": doc_id},
                include=["metadatas"]
            )
            
            if results['ids']:
                self.collection.delete(ids=results['ids'])
                return len(results['ids'])
            return 0
        except Exception as e:
            print(f"Error deleting document: {e}")
            return 0
    
    def get_stats(self) -> Dict:
        """获取数据库统计信息"""
        try:
            count = self.collection.count()
            
            # 计算数据库大小
            db_size = 0
            for root, dirs, files in os.walk(self.db_path):
                for file in files:
                    db_size += os.path.getsize(os.path.join(root, file))
            
            return {
                "total_chunks": count,
                "db_size_bytes": db_size,
                "db_size_mb": round(db_size / (1024 * 1024), 2)
            }
        except Exception as e:
            print(f"Error getting stats: {e}")
            return {"total_chunks": 0, "db_size_bytes": 0, "db_size_mb": 0}
```

#### 4.2 数据库管理工具
```python
# utils/db_manager.py
import os
import shutil
import json
from datetime import datetime
from typing import Dict, List

class DatabaseManager:
    def __init__(self, base_path: str = "./knowledge_bases"):
        self.base_path = base_path
    
    def create_knowledge_base(self, kb_id: str, config: Dict) -> bool:
        """创建新的知识库"""
        kb_path = f"{self.base_path}/{kb_id}"
        
        try:
            # 创建目录结构
            os.makedirs(f"{kb_path}/docs", exist_ok=True)
            os.makedirs(f"{kb_path}/db", exist_ok=True)
            
            # 保存配置文件
            config_data = {
                **config,
                "created_at": datetime.now().isoformat(),
                "db_path": f"{kb_path}/db"
            }
            
            with open(f"{kb_path}/config.json", 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            return True
        except Exception as e:
            print(f"Error creating knowledge base: {e}")
            return False
    
    def delete_knowledge_base(self, kb_id: str) -> bool:
        """删除知识库"""
        kb_path = f"{self.base_path}/{kb_id}"
        
        try:
            if os.path.exists(kb_path):
                shutil.rmtree(kb_path)
                return True
            return False
        except Exception as e:
            print(f"Error deleting knowledge base: {e}")
            return False
    
    def list_knowledge_bases(self) -> List[Dict]:
        """列出所有知识库"""
        knowledge_bases = []
        
        try:
            if not os.path.exists(self.base_path):
                return knowledge_bases
            
            for kb_id in os.listdir(self.base_path):
                kb_path = f"{self.base_path}/{kb_id}"
                config_path = f"{kb_path}/config.json"
                
                if os.path.isdir(kb_path) and os.path.exists(config_path):
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = json.load(f)
                    
                    # 获取统计信息
                    db = VectorDatabase(kb_id, config)
                    stats = db.get_stats()
                    
                    knowledge_bases.append({
                        "kb_id": kb_id,
                        "kb_name": config.get("kb_name", kb_id),
                        "description": config.get("description", ""),
                        "created_at": config.get("created_at", ""),
                        "doc_count": self._count_documents(kb_path),
                        "chunk_count": stats["total_chunks"],
                        "db_size": stats["db_size_mb"]
                    })
        except Exception as e:
            print(f"Error listing knowledge bases: {e}")
        
        return knowledge_bases
    
    def _count_documents(self, kb_path: str) -> int:
        """统计文档数量"""
        docs_path = f"{kb_path}/docs"
        if not os.path.exists(docs_path):
            return 0
        
        count = 0
        for root, dirs, files in os.walk(docs_path):
            count += len([f for f in files if not f.startswith('.')])
        
        return count
    
    def backup_knowledge_base(self, kb_id: str, backup_path: str) -> bool:
        """备份知识库"""
        kb_path = f"{self.base_path}/{kb_id}"
        
        try:
            if os.path.exists(kb_path):
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_name = f"{kb_id}_backup_{timestamp}"
                full_backup_path = f"{backup_path}/{backup_name}"
                
                shutil.copytree(kb_path, full_backup_path)
                
                # 创建备份信息文件
                backup_info = {
                    "kb_id": kb_id,
                    "backup_time": datetime.now().isoformat(),
                    "backup_path": full_backup_path
                }
                
                with open(f"{full_backup_path}/backup_info.json", 'w') as f:
                    json.dump(backup_info, f, indent=2)
                
                return True
            return False
        except Exception as e:
            print(f"Error backing up knowledge base: {e}")
            return False
```

#### 4.3 检索优化
```python
# core/retriever.py
from typing import List, Dict, Optional
import numpy as np

class KnowledgeRetriever:
    def __init__(self, kb_id: str, config: Dict):
        self.kb_id = kb_id
        self.config = config
        self.db = VectorDatabase(kb_id, config)
        self.embeddings = OpenAIEmbeddings(
            model=config.get('embedding_model', 'text-embedding-3-small')
        )
    
    async def retrieve(self, query: str, top_k: int = 5, 
                      filters: Optional[Dict] = None, 
                      min_score: float = 0.6) -> Dict:
        """语义检索"""
        try:
            # 1. 查询向量化
            query_embedding = self.embeddings.embed_query(query)
            
            # 2. 向量检索
            results = self.db.query_documents(
                query_embedding=query_embedding,
                n_results=top_k * 2,  # 多检索一些，后续过滤
                where=filters
            )
            
            if not results or not results['documents'][0]:
                return {
                    "success": True,
                    "query": query,
                    "kb_id": self.kb_id,
                    "chunks": [],
                    "total": 0
                }
            
            # 3. 结果处理和过滤
            chunks = []
            for i, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            )):
                # 转换距离为相似度分数 (0-1)
                similarity_score = 1 - distance
                
                if similarity_score >= min_score:
                    chunks.append({
                        "content": doc,
                        "metadata": metadata,
                        "score": round(similarity_score, 4),
                        "rank": len(chunks) + 1
                    })
                
                if len(chunks) >= top_k:
                    break
            
            return {
                "success": True,
                "query": query,
                "kb_id": self.kb_id,
                "chunks": chunks,
                "total": len(chunks)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "query": query,
                "kb_id": self.kb_id,
                "chunks": [],
                "total": 0
            }
    
    async def multi_kb_retrieve(self, query: str, kb_ids: List[str], 
                               top_k: int = 5) -> Dict:
        """多知识库联合检索"""
        all_chunks = []
        
        for kb_id in kb_ids:
            try:
                # 为每个知识库创建检索器
                retriever = KnowledgeRetriever(kb_id, self.config)
                result = await retriever.retrieve(query, top_k)
                
                if result['success']:
                    for chunk in result['chunks']:
                        chunk['kb_id'] = kb_id
                        all_chunks.append(chunk)
            except Exception as e:
                print(f"Error retrieving from {kb_id}: {e}")
        
        # 按分数排序并取前 top_k
        all_chunks.sort(key=lambda x: x['score'], reverse=True)
        top_chunks = all_chunks[:top_k]
        
        # 重新排序
        for i, chunk in enumerate(top_chunks):
            chunk['rank'] = i + 1
        
        return {
            "success": True,
            "query": query,
            "kb_ids": kb_ids,
            "chunks": top_chunks,
            "total": len(top_chunks)
        }
```

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| 数据持久化 | 向量数据存储在磁盘，重启后数据不丢失 | 服务重启测试 |
| 检索性能 | 单次检索响应时间 < 2秒 | 性能测试 |
| 数据一致性 | 文档删除后相关向量数据也被删除 | 数据一致性检查 |
| 备份恢复 | 支持知识库备份和恢复 | 备份恢复测试 |
| 统计信息 | 准确显示文档数、块数、数据库大小 | 统计数据验证 |
| 多库检索 | 支持跨知识库联合检索 | 多库检索测试 |

---

## 🎯 第五阶段：前端管理界面开发

### 📅 时间安排
**预计工期**: 2-3周

### 🎯 主要任务

#### 5.1 React 项目搭建
```bash
# 创建 React 项目
npx create-react-app frontend --template typescript
cd frontend

# 安装依赖
npm install antd @ant-design/icons
npm install axios zustand
npm install @types/node
npm install react-router-dom
```

#### 5.2 项目结构设计
```

```

#### 5.3 核心组件实现

**知识库管理页面**
```typescript
// pages/KnowledgeBase/index.tsx
import React, { useEffect, useState } from 'react';
import { Table, Button, Modal, Form, Input, message, Space, Popconfirm } from 'antd';
import { PlusOutlined, DeleteOutlined, EditOutlined } from '@ant-design/icons';
import { useKnowledgeBaseStore } from '../../stores/useKnowledgeBase';
import type { KnowledgeBase } from '../../types';

const KnowledgeBasePage: React.FC = () => {
  const [isModalVisible, setIsModalVisible] = useState(false);
  const [form] = Form.useForm();
  const { 
    knowledgeBases, 
    loading, 
    fetchKnowledgeBases, 
    createKnowledgeBase, 
    deleteKnowledgeBase 
  } = useKnowledgeBaseStore();

  useEffect(() => {
    fetchKnowledgeBases();
  }, []);

  const handleCreate = async (values: any) => {
    try {
      await createKnowledgeBase(values);
      message.success('知识库创建成功');
      setIsModalVisible(false);
      form.resetFields();
      fetchKnowledgeBases();
    } catch (error) {
      message.error('创建失败');
    }
  };

  const handleDelete = async (kbId: string) => {
    try {
      await deleteKnowledgeBase(kbId);
      message.success('知识库删除成功');
      fetchKnowledgeBases();
    } catch (error) {
      message.error('删除失败');
    }
  };

  const columns = [
    {
      title: '知识库ID',
      dataIndex: 'kb_id',
      key: 'kb_id',
    },
    {
      title: '知识库名称',
      dataIndex: 'kb_name',
      key: 'kb_name',
    },
    {
      title: '描述',
      dataIndex: 'description',
      key: 'description',
    },
    {
      title: '文档数',
      dataIndex: 'doc_count',
      key: 'doc_count',
    },
    {
      title: '数据块数',
      dataIndex: 'chunk_count',
      key: 'chunk_count',
    },
    {
      title: '数据库大小',
      dataIndex: 'db_size',
      key: 'db_size',
      render: (size: number) => `${size} MB`,
    },
    {
      title: '创建时间',
      dataIndex: 'created_at',
      key: 'created_at',
      render: (date: string) => new Date(date).toLocaleString(),
    },
    {
      title: '操作',
      key: 'action',
      render: (_, record: KnowledgeBase) => (
        <Space size="middle">
          <Button 
            type="link" 
            icon={<EditOutlined />}
            onClick={() => {/* 编辑逻辑 */}}
          >
            编辑
          </Button>
          <Popconfirm
            title="确定要删除这个知识库吗？"
            onConfirm={() => handleDelete(record.kb_id)}
            okText="确定"
            cancelText="取消"
          >
            <Button 
              type="link" 
              danger 
              icon={<DeleteOutlined />}
            >
              删除
            </Button>
          </Popconfirm>
        </Space>
      ),
    },
  ];

  return (
    <div>
      <div style={{ marginBottom: 16 }}>
        <Button 
          type="primary" 
          icon={<PlusOutlined />}
          onClick={() => setIsModalVisible(true)}
        >
          创建知识库
        </Button>
      </div>
      
      <Table 
        columns={columns} 
        dataSource={knowledgeBases}
        rowKey="kb_id"
        loading={loading}
      />

      <Modal
        title="创建知识库"
        visible={isModalVisible}
        onCancel={() => setIsModalVisible(false)}
        footer={null}
      >
        <Form
          form={form}
          layout="vertical"
          onFinish={handleCreate}
        >
          <Form.Item
            name="kb_id"
            label="知识库ID"
            rules={[{ required: true, message: '请输入知识库ID' }]}
          >
            <Input placeholder="例如: crm_system" />
          </Form.Item>
          
          <Form.Item
            name="kb_name"
            label="知识库名称"
            rules={[{ required: true, message: '请输入知识库名称' }]}
          >
            <Input placeholder="例如: CRM系统知识库" />
          </Form.Item>
          
          <Form.Item
            name="description"
            label="描述"
          >
            <Input.TextArea placeholder="知识库描述信息" />
          </Form.Item>
          
          <Form.Item>
            <Space>
              <Button type="primary" htmlType="submit">
                创建
              </Button>
              <Button onClick={() => setIsModalVisible(false)}>
                取消
              </Button>
            </Space>
          </Form.Item>
        </Form>
      </Modal>
    </div>
  );
};

export default KnowledgeBasePage;
```

**文档管理页面**
```typescript
// pages/Documents/index.tsx
import React, { useEffect, useState } from 'react';
import { Upload, Table, Button, message, Progress, Tag, Space } from 'antd';
import { InboxOutlined, DeleteOutlined, ReloadOutlined } from '@ant-design/icons';
import { useDocumentStore } from '../../stores/useDocuments';
import { useKnowledgeBaseStore } from '../../stores/useKnowledgeBase';

const { Dragger } = Upload;

const DocumentsPage: React.FC = () => {
  const [selectedKbId, setSelectedKbId] = useState<string>('');
  const { 
    documents, 
    loading, 
    uploadProgress,
    fetchDocuments, 
    uploadDocuments, 
    deleteDocument 
  } = useDocumentStore();
  const { knowledgeBases } = useKnowledgeBaseStore();

  const uploadProps = {
    name: 'files',
    multiple: true,
    accept: '.txt,.md,.docx,.pdf,.html,.pptx',
    beforeUpload: () => false, // 阻止自动上传
    onChange: async (info: any) => {
      if (info.fileList.length > 0 && selectedKbId) {
        const files = info.fileList.map((file: any) => file.originFileObj);
        await uploadDocuments(selectedKbId, files);
        message.success('文档上传成功，正在后台处理...');
      }
    },
  };

  const columns = [
    {
      title: '文档名称',
      dataIndex: 'filename',
      key: 'filename',
    },
    {
      title: '文档类型',
      dataIndex: 'doc_type',
      key: 'doc_type',
      render: (type: string) => <Tag color="blue">{type}</Tag>,
    },
    {
      title: '处理状态',
      dataIndex: 'status',
      key: 'status',
      render: (status: string) => {
        const colors = {
          'processing': 'orange',
          'completed': 'green',
          'failed': 'red'
        };
        return <Tag color={colors[status as keyof typeof colors]}>{status}</Tag>;
      },
    },
    {
      title: '数据块数',
      dataIndex: 'chunk_count',
      key: 'chunk_count',
    },
    {
      title: '上传时间',
      dataIndex: 'upload_time',
      key: 'upload_time',
      render: (time: string) => new Date(time).toLocaleString(),
    },
    {
      title: '操作',
      key: 'action',
      render: (_, record: any) => (
        <Space size="middle">
          {record.status === 'failed' && (
            <Button 
              type="link" 
              icon={<ReloadOutlined />}
              onClick={() => {/* 重新处理逻辑 */}}
            >
              重新处理
            </Button>
          )}
          <Button 
            type="link" 
            danger 
            icon={<DeleteOutlined />}
            onClick={() => deleteDocument(selectedKbId, record.doc_id)}
          >
            删除
          </Button>
        </Space>
      ),
    },
  ];

  return (
    <div>
      <div style={{ marginBottom: 16 }}>
        <select 
          value={selectedKbId} 
          onChange={(e) => setSelectedKbId(e.target.value)}
          style={{ marginRight: 16, padding: '4px 8px' }}
        >
          <option value="">选择知识库</option>
          {knowledgeBases.map(kb => (
            <option key={kb.kb_id} value={kb.kb_id}>
              {kb.kb_name}
            </option>
          ))}
        </select>
      </div>

      {selectedKbId && (
        <>
          <Dragger {...uploadProps} style={{ marginBottom: 16 }}>
            <p className="ant-upload-drag-icon">
              <InboxOutlined />
            </p>
            <p className="ant-upload-text">点击或拖拽文件到此区域上传</p>
            <p className="ant-upload-hint">
              支持 .txt, .md, .docx, .pdf, .html, .pptx 格式
            </p>
          </Dragger>

          {uploadProgress > 0 && uploadProgress < 100 && (
            <Progress percent={uploadProgress} style={{ marginBottom: 16 }} />
          )}

          <Table 
            columns={columns} 
            dataSource={documents}
            rowKey="doc_id"
            loading={loading}
          />
        </>
      )}
    </div>
  );
};

export default DocumentsPage;
```

#### 5.4 状态管理
```typescript
// stores/useKnowledgeBase.ts
import { create } from 'zustand';
import { knowledgeBaseApi } from '../services/knowledgeBase';
import type { KnowledgeBase } from '../types';

interface KnowledgeBaseState {
  knowledgeBases: KnowledgeBase[];
  currentKb: KnowledgeBase | null;
  loading: boolean;
  fetchKnowledgeBases: () => Promise<void>;
  createKnowledgeBase: (data: any) => Promise<void>;
  deleteKnowledgeBase: (kbId: string) => Promise<void>;
  setCurrentKb: (kb: KnowledgeBase) => void;
}

export const useKnowledgeBaseStore = create<KnowledgeBaseState>((set, get) => ({
  knowledgeBases: [],
  currentKb: null,
  loading: false,

  fetchKnowledgeBases: async () => {
    set({ loading: true });
    try {
      const data = await knowledgeBaseApi.list();
      set({ knowledgeBases: data, loading: false });
    } catch (error) {
      set({ loading: false });
      throw error;
    }
  },

  createKnowledgeBase: async (data) => {
    await knowledgeBaseApi.create(data);
  },

  deleteKnowledgeBase: async (kbId) => {
    await knowledgeBaseApi.delete(kbId);
  },

  setCurrentKb: (kb) => {
    set({ currentKb: kb });
  },
}));
```

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| 界面响应 | 页面加载时间 < 3秒，操作响应 < 1秒 | 性能测试 |
| 功能完整 | 知识库CRUD、文档上传、检索测试功能正常 | 功能测试 |
| 用户体验 | 界面美观，操作流畅，错误提示友好 | 用户体验测试 |
| 兼容性 | 支持主流浏览器（Chrome, Firefox, Safari） | 浏览器兼容性测试 |
| 响应式 | 支持不同屏幕尺寸 | 响应式测试 |
| 状态管理 | 数据状态同步正确，无内存泄漏 | 状态管理测试 |

---

## 🎯 第六阶段：Dify集成与API对接

### 📅 时间安排
**预计工期**: 1周

### 🎯 主要任务

#### 6.1 Dify API 工具配置
```json
{
  "name": "Knowledge Retrieval",
  "description": "从企业知识库中检索相关信息",
  "url": "http://your-domain:8000/api/retrieve",
  "method": "POST",
  "headers": {
    "Content-Type": "application/json"
  },
  "parameters": {
    "query": {
      "type": "string",
      "description": "用户查询问题",
      "required": true
    },
    "kb_id": {
      "type": "string", 
      "description": "知识库ID",
      "required": true,
      "default": "crm_system"
    },
    "top_k": {
      "type": "integer",
      "description": "返回结果数量",
      "default": 5
    },
    "min_score": {
      "type": "number",
      "description": "最小相似度分数",
      "default": 0.6
    }
  }
}
```

#### 6.2 检索接口优化
```python
# api/retrieve.py - 为 Dify 优化的检索接口
@router.post("/retrieve", response_model=RetrieveResponse)
async def retrieve_for_dify(request: RetrieveRequest):
    """
    为 Dify 优化的检索接口
    返回格式化的知识内容
    """
    try:
        # 加载知识库配置
        config = load_kb_config(request.kb_id)
        if not config:
            raise HTTPException(status_code=404, detail=f"Knowledge base {request.kb_id} not found")
        
        # 执行检索
        retriever = KnowledgeRetriever(request.kb_id, config)
        result = await retriever.retrieve(
            query=request.query,
            top_k=request.top_k,
            filters=request.filters,
            min_score=request.min_score
        )
        
        if not result['success']:
            raise HTTPException(status_code=500, detail=result.get('error', 'Retrieval failed'))
        
        # 格式化返回结果，便于 Dify 使用
        formatted_chunks = []
        for chunk in result['chunks']:
            formatted_chunks.append({
                "content": chunk['content'],
                "source": chunk['metadata'].get('filename', 'unknown'),
                "doc_type": chunk['metadata'].get('doc_type', 'unknown'),
                "system": chunk['metadata'].get('system', 'unknown'),
                "score": chunk['score'],
                "rank": chunk['rank']
            })
        
        # 生成摘要文本（供 Dify 直接使用）
        summary_text = generate_summary_text(formatted_chunks, request.query)
        
        return RetrieveResponse(
            success=True,
            query=request.query,
            kb_id=request.kb_id,
            chunks=formatted_chunks,
            total=len(formatted_chunks),
            summary=summary_text  # 新增摘要字段
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Retrieval error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def generate_summary_text(chunks: List[Dict], query: str) -> str:
    """
    生成检索结果摘要文本
    供 Dify 工作流直接使用
    """
    if not chunks:
        return f"未找到与 '{query}' 相关的信息。"
    
    summary_parts = [f"根据查询 '{query}'，找到以下相关信息：\n"]
    
    for i, chunk in enumerate(chunks[:3], 1):  # 只取前3个最相关的
        summary_parts.append(
            f"{i}. 来源：{chunk['source']} ({chunk['doc_type']})\n"
            f"   内容：{chunk['content'][:200]}...\n"
            f"   相关度：{chunk['score']:.2f}\n"
        )
    
    if len(chunks) > 3:
        summary_parts.append(f"\n另外还找到 {len(chunks) - 3} 条相关信息。")
    
    return "\n".join(summary_parts)
```

#### 6.3 Dify 工作流集成示例
```yaml
# Dify 工作流配置示例
workflow:
  name: "企业知识问答"
  description: "基于企业知识库的智能问答"
  
  nodes:
    - id: "start"
      type: "start"
      data:
        title: "开始"
        variables:
          - name: "user_query"
            type: "string"
            description: "用户问题"
    
    - id: "knowledge_retrieval"
      type: "tool"
      data:
        title: "知识检索"
        tool_name: "Knowledge Retrieval"
        tool_parameters:
          query: "{{#start.user_query#}}"
          kb_id: "crm_system"
          top_k: 5
          min_score: 0.6
    
    - id: "llm_answer"
      type: "llm"
      data:
        title: "生成答案"
        model: "gpt-3.5-turbo"
        prompt: |
          你是一个企业知识助手。基于以下检索到的知识内容，回答用户的问题。
          
          用户问题：{{#start.user_query#}}
          
          检索到的知识：
          {{#knowledge_retrieval.summary#}}
          
          请基于上述知识内容，给出准确、详细的回答。如果知识内容不足以回答问题，请说明需要更多信息。
    
    - id: "end"
      type: "end"
      data:
        title: "结束"
        outputs:
          - name: "answer"
            type: "string"
            value: "{{#llm_answer.text#}}"
          - name: "sources"
            type: "array"
            value: "{{#knowledge_retrieval.chunks#}}"

  edges:
    - source: "start"
      target: "knowledge_retrieval"
    - source: "knowledge_retrieval"
      target: "llm_answer"
    - source: "llm_answer"
      target: "end"
```

#### 6.4 集成测试工具
```python
# tests/test_dify_integration.py
import asyncio
import httpx
import json

class DifyIntegrationTester:
    def __init__(self, api_base_url: str, dify_api_key: str):
        self.api_base_url = api_base_url
        self.dify_api_key = dify_api_key
    
    async def test_retrieve_api(self):
        """测试检索 API"""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.api_base_url}/api/retrieve",
                json={
                    "query": "如何配置用户权限",
                    "kb_id": "crm_system",
                    "top_k": 5,
                    "min_score": 0.6
                }
            )
            
            assert response.status_code == 200
            data = response.json()
            assert data['success'] == True
            assert len(data['chunks']) > 0
            
            print(f"✅ 检索测试通过，返回 {data['total']} 条结果")
            return data
    
    async def test_dify_workflow(self, user_query: str):
        """测试 Dify 工作流"""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.dify.ai/v1/workflows/run",
                headers={
                    "Authorization": f"Bearer {self.dify_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "inputs": {
                        "user_query": user_query
                    },
                    "response_mode": "blocking"
                }
            )
            
            assert response.status_code == 200
            data = response.json()
            
            print(f"✅ Dify 工作流测试通过")
            print(f"用户问题：{user_query}")
            print(f"AI 回答：{data['data']['outputs']['answer']}")
            
            return data

# 运行测试
async def run_integration_tests():
    tester = DifyIntegrationTester(
        api_base_url="http://localhost:8000",
        dify_api_key="your-dify-api-key"
    )
    
    # 测试检索 API
    await tester.test_retrieve_api()
    
    # 测试 Dify 工作流
    test_queries = [
        "如何配置用户权限？",
        "系统登录流程是什么？",
        "如何处理客户投诉？"
    ]
    
    for query in test_queries:
        await tester.test_dify_workflow(query)

if __name__ == "__main__":
    asyncio.run(run_integration_tests())
```

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| API 对接 | Dify 能成功调用检索接口 | API 调用测试 |
| 数据格式 | 返回数据格式符合 Dify 要求 | 数据格式验证 |
| 工作流集成 | Dify 工作流能正常运行 | 工作流测试 |
| 响应时间 | API 响应时间 < 3秒 | 性能测试 |
| 错误处理 | 异常情况有合适的错误返回 | 异常测试 |
| 文档完整 | 集成文档和示例完整 | 文档检查 |

---

## 🎯 第七阶段：系统测试与性能优化

### 📅 时间安排
**预计工期**: 1-2周

### 🎯 主要任务

#### 7.1 功能测试
```python
# tests/test_functional.py
import pytest
import asyncio
from httpx import AsyncClient
from fastapi.testclient import TestClient
from main import app

class TestKnowledgeBase:
    def setup_class(self):
        self.client = TestClient(app)
    
    def test_create_knowledge_base(self):
        """测试创建知识库"""
        response = self.client.post("/api/kb/create", json={
            "kb_id": "test_kb",
            "kb_name": "测试知识库",
            "description": "用于测试的知识库"
        })
        assert response.status_code == 200
        assert response.json()["success"] == True
    
    def test_upload_document(self):
        """测试文档上传"""
        with open("test_document.txt", "rb") as f:
            response = self.client.post(
                "/api/kb/test_kb/documents/upload",
                files={"files": ("test.txt", f, "text/plain")}
            )
        assert response.status_code == 200
    
    def test_retrieve_knowledge(self):
        """测试知识检索"""
        response = self.client.post("/api/retrieve", json={
            "query": "测试查询",
            "kb_id": "test_kb",
            "top_k": 5
        })
        assert response.status_code == 200
        data = response.json()
        assert "chunks" in data
```

#### 7.2 性能测试
```python
# tests/test_performance.py
import asyncio
import time
import statistics
from concurrent.futures import ThreadPoolExecutor
import httpx

class PerformanceTest:
    def __init__(self, base_url: str):
        self.base_url = base_url
    
    async def test_concurrent_retrieval(self, concurrent_users: int = 10):
        """测试并发检索性能"""
        async def single_request():
            async with httpx.AsyncClient() as client:
                start_time = time.time()
                response = await client.post(
                    f"{self.base_url}/api/retrieve",
                    json={
                        "query": "测试查询",
                        "kb_id": "test_kb",
                        "top_k": 5
                    }
                )
                end_time = time.time()
                return end_time - start_time, response.status_code
        
        # 并发测试
        tasks = [single_request() for _ in range(concurrent_users)]
        results = await asyncio.gather(*tasks)
        
        response_times = [r[0] for r in results]
        status_codes = [r[1] for r in results]
        
        # 性能指标
        avg_response_time = statistics.mean(response_times)
        max_response_time = max(response_times)
        success_rate = sum(1 for code in status_codes if code == 200) / len(status_codes)
        
        print(f"并发用户数: {concurrent_users}")
        print(f"平均响应时间: {avg_response_time:.2f}s")
        print(f"最大响应时间: {max_response_time:.2f}s")
        print(f"成功率: {success_rate:.2%}")
        
        # 性能要求验证
        assert avg_response_time < 2.0, f"平均响应时间超标: {avg_response_time}s"
        assert success_rate > 0.95, f"成功率过低: {success_rate}"
    
    def test_memory_usage(self):
        """测试内存使用情况"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # 执行大量操作
        for i in range(100):
            # 模拟文档处理
            pass
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        print(f"初始内存: {initial_memory:.2f} MB")
        print(f"最终内存: {final_memory:.2f} MB")
        print(f"内存增长: {memory_increase:.2f} MB")
        
        # 内存泄漏检查
        assert memory_increase < 100, f"内存增长过多: {memory_increase} MB"
```

#### 7.3 安全测试
```python
# tests/test_security.py
import requests
import json

class SecurityTest:
    def __init__(self, base_url: str):
        self.base_url = base_url
    
    def test_sql_injection(self):
        """测试 SQL 注入防护"""
        malicious_queries = [
            "'; DROP TABLE users; --",
            "' OR '1'='1",
            "admin'--",
            "' UNION SELECT * FROM users --"
        ]
        
        for query in malicious_queries:
            response = requests.post(
                f"{self.base_url}/api/retrieve",
                json={"query": query, "kb_id": "test_kb"}
            )
            # 应该正常处理，不应该出现数据库错误
            assert response.status_code in [200, 400]
    
    def test_xss_protection(self):
        """测试 XSS 防护"""
        xss_payloads = [
            "<script>alert('xss')</script>",
            "javascript:alert('xss')",
            "<img src=x onerror=alert('xss')>"
        ]
        
        for payload in xss_payloads:
            response = requests.post(
                f"{self.base_url}/api/kb/create",
                json={
                    "kb_id": "test",
                    "kb_name": payload,
                    "description": payload
                }
            )
            # 检查响应中是否包含未转义的脚本
            if response.status_code == 200:
                assert "<script>" not in response.text
    
    def test_file_upload_security(self):
        """测试文件上传安全性"""
        # 测试恶意文件上传
        malicious_files = [
            ("test.exe", b"MZ\x90\x00"),  # 可执行文件
            ("test.php", b"<?php system($_GET['cmd']); ?>"),  # PHP 脚本
            ("../../../etc/passwd", b"root:x:0:0:root:/root:/bin/bash")  # 路径遍历
        ]
        
        for filename, content in malicious_files:
            response = requests.post(
                f"{self.base_url}/api/kb/test_kb/documents/upload",
                files={"files": (filename, content, "text/plain")}
            )
            # 应该拒绝恶意文件
            assert response.status_code in [400, 403, 415]
```

#### 7.4 监控配置
```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
import functools

# 定义监控指标
REQUEST_COUNT = Counter('api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('api_request_duration_seconds', 'API request duration')
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Active connections')
KNOWLEDGE_BASE_COUNT = Gauge('knowledge_bases_total', 'Total knowledge bases')
DOCUMENT_COUNT = Gauge('documents_total', 'Total documents')

def monitor_requests(func):
    """API 请求监控装饰器"""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            REQUEST_COUNT.labels(method='POST', endpoint=func.__name__, status='success').inc()
            return result
        except Exception as e:
            REQUEST_COUNT.labels(method='POST', endpoint=func.__name__, status='error').inc()
            raise
        finally:
            REQUEST_DURATION.observe(time.time() - start_time)
    
    return wrapper

class SystemMonitor:
    def __init__(self):
        self.start_time = time.time()
    
    def update_metrics(self):
        """更新系统指标"""
        # 更新知识库数量
        kb_count = len(self.get_knowledge_bases())
        KNOWLEDGE_BASE_COUNT.set(kb_count)
        
        # 更新文档数量
        doc_count = self.get_total_document_count()
        DOCUMENT_COUNT.set(doc_count)
    
    def start_metrics_server(self, port: int = 8001):
        """启动监控指标服务器"""
        start_http_server(port)
        print(f"Metrics server started on port {port}")
```

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| 功能测试 | 所有核心功能测试通过率 > 95% | 自动化测试 |
| 性能测试 | 并发50用户，平均响应时间 < 2秒 | 压力测试 |
| 安全测试 | 通过 SQL 注入、XSS、文件上传安全测试 | 安全扫描 |
| 监控系统 | 关键指标监控正常，告警机制有效 | 监控测试 |
| 错误处理 | 异常情况有合适的错误码和信息 | 异常测试 |
| 日志记录 | 关键操作有完整的日志记录 | 日志检查 |

---

## 🎯 第八阶段：生产部署与运维

### 📅 时间安排
**预计工期**: 1-2周

### 🎯 主要任务

#### 8.1 Docker 容器化
```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY backend/ ./backend/
COPY knowledge_bases/ ./knowledge_bases/

# 设置环境变量
ENV PYTHONPATH=/app/backend
ENV PYTHONUNBUFFERED=1

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "8000"]
```



```yaml
# docker-compose.yml
version: '3.8'

services:
  knowledge-hub-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DB_PATH=/app/knowledge_bases
    volumes:
      - ./knowledge_bases:/app/knowledge_bases
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  knowledge-hub-frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - knowledge-hub-api
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - knowledge-hub-api
      - knowledge-hub-frontend
    restart: unless-stopped

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    restart: unless-stopped

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana-storage:/var/lib/grafana
    restart: unless-stopped

volumes:
  grafana-storage:
```

#### 8.2 生产环境配置
```bash
#!/bin/bash
# scripts/deploy.sh - 生产部署脚本

set -e

echo "🚀 开始部署企业级知识中台..."

# 1. 环境检查
echo "📋 检查部署环境..."
if ! command -v docker &> /dev/null; then
    echo "❌ Docker 未安装"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "❌ Docker Compose 未安装"
    exit 1
fi

# 2. 创建必要目录
echo "📁 创建目录结构..."
mkdir -p knowledge_bases
mkdir -p logs
mkdir -p ssl
mkdir -p backups

# 3. 设置权限
echo "🔐 设置文件权限..."
chmod 755 knowledge_bases
chmod 755 logs
chmod 600 .env

# 4. 构建镜像
echo "🏗️ 构建 Docker 镜像..."
docker-compose build --no-cache

# 5. 启动服务
echo "🚀 启动服务..."
docker-compose up -d

# 6. 健康检查
echo "🏥 等待服务启动..."
sleep 30

if curl -f http://localhost:8000/health; then
    echo "✅ API 服务启动成功"
else
    echo "❌ API 服务启动失败"
    docker-compose logs knowledge-hub-api
    exit 1
fi

if curl -f http://localhost:3000; then
    echo "✅ 前端服务启动成功"
else
    echo "❌ 前端服务启动失败"
    docker-compose logs knowledge-hub-frontend
    exit 1
fi

echo "🎉 部署完成！"
echo "📊 访问地址："
echo "   - API 文档: http://localhost:8000/docs"
echo "   - 管理界面: http://localhost:3000"
echo "   - 监控面板: http://localhost:3001"
```

#### 8.3 备份策略
```bash
#!/bin/bash
# scripts/backup.sh - 数据备份脚本

BACKUP_DIR="/opt/backups/knowledge-hub"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="knowledge_hub_backup_${DATE}"

echo "📦 开始备份知识中台数据..."

# 创建备份目录
mkdir -p ${BACKUP_DIR}/${BACKUP_NAME}

# 1. 备份知识库数据
echo "💾 备份知识库数据..."
cp -r ./knowledge_bases ${BACKUP_DIR}/${BACKUP_NAME}/

# 2. 备份配置文件
echo "⚙️ 备份配置文件..."
cp .env ${BACKUP_DIR}/${BACKUP_NAME}/
cp docker-compose.yml ${BACKUP_DIR}/${BACKUP_NAME}/

# 3. 备份数据库
echo "🗄️ 备份向量数据库..."
docker-compose exec knowledge-hub-api python -c "
import os
import shutil
from datetime import datetime

# 创建数据库快照
for kb_dir in os.listdir('./knowledge_bases'):
    kb_path = f'./knowledge_bases/{kb_dir}'
    if os.path.isdir(kb_path):
        # 这里可以添加数据库特定的备份逻辑
        pass
"

# 4. 压缩备份
echo "🗜️ 压缩备份文件..."
cd ${BACKUP_DIR}
tar -czf ${BACKUP_NAME}.tar.gz ${BACKUP_NAME}
rm -rf ${BACKUP_NAME}

# 5. 清理旧备份（保留最近7天）
echo "🧹 清理旧备份..."
find ${BACKUP_DIR} -name "knowledge_hub_backup_*.tar.gz" -mtime +7 -delete

echo "✅ 备份完成: ${BACKUP_DIR}/${BACKUP_NAME}.tar.gz"

# 6. 上传到云存储（可选）
if [ ! -z "$CLOUD_BACKUP_ENABLED" ]; then
    echo "☁️ 上传到云存储..."
    # 这里添加云存储上传逻辑
    # aws s3 cp ${BACKUP_DIR}/${BACKUP_NAME}.tar.gz s3://your-backup-bucket/
fi
```

#### 8.4 监控告警
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'knowledge-hub-api'
    static_configs:
      - targets: ['knowledge-hub-api:8001']
    metrics_path: /metrics
    scrape_interval: 5s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

```yaml
# monitoring/alert_rules.yml
groups:
  - name: knowledge-hub-alerts
    rules:
      - alert: HighResponseTime
        expr: api_request_duration_seconds > 5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "API 响应时间过长"
          description: "API 响应时间超过 5 秒"

      - alert: HighErrorRate
        expr: rate(api_requests_total{status="error"}[5m]) > 0.1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "API 错误率过高"
          description: "API 错误率超过 10%"

      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "服务不可用"
          description: "知识中台服务已停止"
```

### ✅ 验收标准

| 验收项 | 验收标准 | 验证方法 |
|--------|----------|----------|
| 容器化部署 | Docker 镜像构建成功，服务正常启动 | 部署测试 |
| 服务可用性 | 服务可用性 > 99.5% | 可用性监控 |
| 数据备份 | 自动备份正常，恢复测试成功 | 备份恢复测试 |
| 监控告警 | 关键指标监控，异常及时告警 | 告警测试 |
| 安全配置 | HTTPS 配置，访问控制正常 | 安全检查 |
| 文档完整 | 部署文档、运维手册完整 | 文档检查 |

---

## 📊 项目总结

### 🎯 项目成果
1. **完整的知识中台系统**：支持多知识库管理、智能文档处理、语义检索
2. **现代化技术架构**：基于 FastAPI + React + ChromaDB + Dify
3. **生产级部署方案**：Docker 容器化、监控告警、备份恢复
4. **完善的测试体系**：功能测试、性能测试、安全测试

### 📈 技术指标
- **处理能力**：支持 TB 级文档存储，千万级向量检索
- **响应性能**：平均检索响应时间 < 2秒
- **并发能力**：支持 100+ 并发用户
- **可用性**：系统可用性 > 99.5%

### 🔧 运维要求
- **硬件配置**：8核CPU，32GB内存，1TB SSD存储
- **网络要求**：稳定的互联网连接（OpenAI API）
- **维护周期**：每周数据备份，每月系统更新
- **监控检查**：7x24小时系统监控

### 📚 交付物清单
1. ✅ 完整的源代码
2. ✅ 部署脚本和配置文件
3. ✅ 用户使用手册
4. ✅ 运维操作手册
5. ✅ API 接口文档
6. ✅ 测试报告
7. ✅ 监控配置

---

## 📞 技术支持

### 🆘 常见问题
1. **文档处理失败**：检查文件格式和大小限制
2. **检索结果不准确**：调整分块大小和相似度阈值
3. **系统响应慢**：检查向量数据库索引和硬件资源
4. **Dify 集成问题**：验证 API 接口和参数格式

### 📧 联系方式
- **技术支持**：tech-support@company.com
- **项目经理**：project-manager@company.com
- **紧急联系**：+86-xxx-xxxx-xxxx

---

*本文档版本：v1.0 | 最后更新：2024年1月*